{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278d8887953fc18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:02:52.145007Z",
     "start_time": "2024-12-18T01:02:50.183614Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM\n",
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "from segmentation_models_pytorch.utils.metrics import IoU\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from model.voc.config import *\n",
    "from model.voc.retrain_with_xai import VOCDataset, get_training_augmentation, get_preprocessing, \\\n",
    "    get_validation_augmentation\n",
    "from utils import DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de6c795f8a4145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:02:52.171170Z",
     "start_time": "2024-12-18T01:02:52.169135Z"
    }
   },
   "outputs": [],
   "source": [
    "%env PYTHONPATH=\"/home/r6639/Projects/xaiseg\":$PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae52701bbbff542",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:02:52.253398Z",
     "start_time": "2024-12-18T01:02:52.251996Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = len(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78eebb0cc4ecb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:02:52.312611Z",
     "start_time": "2024-12-18T01:02:52.311058Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradcam_heatmap(model, target_layer, input_tensor, masks):\n",
    "    # input_tensor.requires_grad = True  # Already set in the forward method\n",
    "    cam = HiResCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "    targets = []\n",
    "    for i in range(input_tensor.size(0)):\n",
    "        target = SemanticSegmentationTarget(category=None, mask=masks[i])\n",
    "        targets.append(target)\n",
    "\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    return grayscale_cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc609d95c8dcf23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:02:52.374711Z",
     "start_time": "2024-12-18T01:02:52.372998Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_activation(model, target_layer, x):\n",
    "    activations = []\n",
    "\n",
    "    def hook(module, input, output):\n",
    "        activations.append(output)\n",
    "\n",
    "    handle = target_layer.register_forward_hook(hook)\n",
    "    _ = model(x)\n",
    "    handle.remove()\n",
    "    return activations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e6b79e6dc2901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T03:22:57.175Z",
     "start_time": "2024-12-18T03:22:57.172317Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_heatmap(heatmap):\n",
    "    # Compute the minimum and maximum values along the specified dimensions\n",
    "    heatmap_min = heatmap.min(dim=1, keepdim=True)[0].min(dim=2, keepdim=True)[0]\n",
    "    heatmap_max = heatmap.max(dim=1, keepdim=True)[0].max(dim=2, keepdim=True)[0]\n",
    "\n",
    "    # Normalize the heatmap using broadcasting\n",
    "    normalized_heatmap = (heatmap - heatmap_min) / (heatmap_max - heatmap_min + 1e-8)\n",
    "    return normalized_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f6a38ce276529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T03:22:49.128439Z",
     "start_time": "2024-12-18T03:22:49.122541Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, optimizer, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def __call__(self, val_loss, model, path_name):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path_name)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter == 5:\n",
    "                self.optimizer.param_groups[0]['lr'] = 1e-5\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path_name)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path_name):\n",
    "        \"\"\"Saves model when validation loss decrease.\"\"\"\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path_name)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9acbeaf1c2d5c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T03:22:51.721711Z",
     "start_time": "2024-12-18T03:22:51.716209Z"
    }
   },
   "outputs": [],
   "source": [
    "class GradCAMDistillationLossAlpha(torch.nn.Module):\n",
    "    def __init__(self, student_loss_fn, teacher_model, student_model, distillation_weight, soft_label_weight,\n",
    "                 temperature=1.0):\n",
    "        super(GradCAMDistillationLossAlpha, self).__init__()\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.teacher_model = teacher_model\n",
    "        self.student_model = student_model\n",
    "        self.distillation_weight = distillation_weight\n",
    "        self.soft_label_weight = soft_label_weight\n",
    "        self.temperature = temperature\n",
    "        self.kl_div_loss_fn = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "    def forward(self, student_output, y_true, x_tensor, compute_gradcam=True):\n",
    "        # Compute the student's segmentation loss\n",
    "        student_loss = self.student_loss_fn(student_output, y_true)\n",
    "\n",
    "        # Obtain teacher's outputs (soft labels)\n",
    "        with torch.no_grad():\n",
    "            teacher_output = self.teacher_model(x_tensor)\n",
    "\n",
    "        # Compute the soft label loss (KL Divergence)\n",
    "        # Apply temperature scaling\n",
    "        student_logits = student_output / self.temperature\n",
    "        teacher_logits = teacher_output / self.temperature\n",
    "\n",
    "        # Compute probabilities\n",
    "        student_log_probs = F.log_softmax(student_logits, dim=1)\n",
    "        teacher_probs = F.softmax(teacher_logits, dim=1)\n",
    "\n",
    "        # Compute KL Divergence\n",
    "        soft_label_loss = self.kl_div_loss_fn(student_log_probs, teacher_probs) * (self.temperature ** 2)\n",
    "\n",
    "        distillation_loss = 0.0  # Default value\n",
    "\n",
    "        if compute_gradcam:\n",
    "            # Ensure x_tensor requires gradients\n",
    "            x_tensor.requires_grad = True\n",
    "\n",
    "            # Compute Grad-CAM heatmaps\n",
    "            # Student masks (student predictions)\n",
    "            student_masks = torch.argmax(student_output, dim=1).float()\n",
    "\n",
    "            # Teacher masks (teacher predictions)\n",
    "            teacher_masks = torch.argmax(teacher_output, dim=1).float()\n",
    "\n",
    "            # Compute Grad-CAM heatmaps for teacher and student\n",
    "            teacher_heatmap = compute_gradcam_heatmap(\n",
    "                model=self.teacher_model,\n",
    "                target_layer=self.teacher_model.decoder.block1,\n",
    "                input_tensor=x_tensor,\n",
    "                masks=teacher_masks\n",
    "            )\n",
    "            student_heatmap = compute_gradcam_heatmap(\n",
    "                model=self.student_model,\n",
    "                target_layer=self.student_model.decoder.block1,\n",
    "                input_tensor=x_tensor,\n",
    "                masks=student_masks\n",
    "            )\n",
    "\n",
    "            # Convert heatmaps to torch tensors and move to device\n",
    "            teacher_heatmap = torch.from_numpy(teacher_heatmap).float().to(student_output.device)\n",
    "            student_heatmap = torch.from_numpy(student_heatmap).float().to(student_output.device)\n",
    "\n",
    "            # Normalize heatmaps\n",
    "            teacher_heatmap = normalize_heatmap(teacher_heatmap)\n",
    "            student_heatmap = normalize_heatmap(student_heatmap)\n",
    "\n",
    "            # Compute distillation loss between heatmaps\n",
    "            distillation_loss = F.mse_loss(student_heatmap, teacher_heatmap)\n",
    "\n",
    "        # Combine the losses\n",
    "        total_loss = (\n",
    "                student_loss\n",
    "                + self.soft_label_weight * soft_label_loss\n",
    "                + self.distillation_weight * distillation_loss\n",
    "        )\n",
    "\n",
    "        return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d092c8d812fe7148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:04:34.510678Z",
     "start_time": "2024-12-18T01:04:34.508192Z"
    }
   },
   "outputs": [],
   "source": [
    "class SemanticSegmentationTarget:\n",
    "    def __init__(self, category, mask):\n",
    "        self.category = category\n",
    "        # Ensure mask is a torch tensor\n",
    "        if isinstance(mask, np.ndarray):\n",
    "            self.mask = torch.from_numpy(mask).float()\n",
    "        else:\n",
    "            self.mask = mask.float()\n",
    "        if torch.cuda.is_available():\n",
    "            self.mask = self.mask.cuda()\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        # model_output shape: (C, H, W)\n",
    "        if self.category is not None:\n",
    "            output = model_output[self.category, :, :]\n",
    "        else:\n",
    "            output = model_output.sum(dim=0)\n",
    "        loss = (output * self.mask).sum()\n",
    "        # Add epsilon to prevent zero gradients\n",
    "        loss += 1e-6\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb6fc3c4fd00234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:04:34.858483Z",
     "start_time": "2024-12-18T01:04:34.856744Z"
    }
   },
   "outputs": [],
   "source": [
    "class NamedDiceLoss(DiceLoss):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__name__ = \"DiceLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb7297779d8a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:04:35.321601Z",
     "start_time": "2024-12-18T01:04:35.319123Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "            # Get predictions\n",
    "            output = model(x_batch)\n",
    "\n",
    "            # Compute loss (use DiceLoss for evaluation)\n",
    "            loss = DiceLoss(mode='multiclass')(output, y_batch)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            test_loss += loss.item()\n",
    "            y_pred = torch.argmax(output, dim=1)\n",
    "            y_true = torch.argmax(y_batch, dim=1)\n",
    "            iou = IoU()(y_pred, y_true)\n",
    "            test_iou += iou.item()\n",
    "\n",
    "    # Compute average loss and IoU\n",
    "    test_loss /= len(dataloader)\n",
    "    test_iou /= len(dataloader)\n",
    "\n",
    "    return test_loss, test_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca93b188589266",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d4596b56ec469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T03:23:11.489485Z",
     "start_time": "2024-12-18T03:23:11.478360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = VOCDataset(x_train_dir, y_train_dir, augmentation=get_training_augmentation(),\n",
    "                           preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "val_dataset = VOCDataset(x_val_dir, y_val_dir, augmentation=get_validation_augmentation(),\n",
    "                         preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "test_dataset = VOCDataset(x_test_dir, y_test_dir, augmentation=get_validation_augmentation(),\n",
    "                          preprocessing=get_preprocessing(preprocessing_fn))\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=12)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3db854dcadf50",
   "metadata": {},
   "source": [
    "## Train Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b04e9eaf532c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")\n",
    "teacher_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07504e2aab808e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, metrics, and optimizer for the teacher model\n",
    "teacher_loss_fn = NamedDiceLoss(mode='multiclass')\n",
    "metrics = [IoU(threshold=0.5)]\n",
    "teacher_optimizer = torch.optim.Adam(teacher_model.parameters(), lr=0.0001)\n",
    "# Early Stopping Initialization\n",
    "early_stopping = EarlyStopping(optimizer=teacher_optimizer, patience=30, verbose=True)\n",
    "# Training loop for the teacher model\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    teacher_model.train()\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_loader):\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "        # Get teacher predictions\n",
    "        teacher_output = teacher_model(x_batch)\n",
    "\n",
    "        # Compute the loss for the teacher model\n",
    "        loss = teacher_loss_fn(teacher_output, y_batch)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        teacher_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        teacher_optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        train_loss += loss.item()\n",
    "        # Compute IoU for the batch\n",
    "        y_pred = torch.argmax(teacher_output, dim=1)  # Shape: (N, H, W)\n",
    "        y_true = y_batch.squeeze(1)  # Remove channel dimension if present\n",
    "        iou = IoU()(y_pred, y_true)\n",
    "        train_iou += iou.item()\n",
    "\n",
    "    # Compute average training loss and IoU\n",
    "    train_loss /= len(train_loader)\n",
    "    train_iou /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    teacher_model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "            # Get teacher predictions\n",
    "            teacher_output = teacher_model(x_batch)\n",
    "\n",
    "            # Compute the validation loss\n",
    "            loss = teacher_loss_fn(teacher_output, y_batch)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            val_loss += loss.item()\n",
    "            y_pred = torch.argmax(teacher_output, dim=1)\n",
    "            y_true = torch.argmax(y_batch, dim=1)\n",
    "            iou = IoU()(y_pred, y_true)\n",
    "            val_iou += iou.item()\n",
    "\n",
    "    # Compute average validation loss and IoU\n",
    "    val_loss /= len(val_loader)\n",
    "    val_iou /= len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch} - Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}')\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(val_loss, teacher_model, 'teacher_model.pth')\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb908e658443451",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.eval()  # Set teacher model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a56eb9036a128",
   "metadata": {},
   "source": [
    "## Train Student Model without any distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb804c8d37c6234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the student model\n",
    "ENCODER_STUDENT = 'resnet18'\n",
    "student_model = smp.PSPNet(\n",
    "    encoder_name=ENCODER_STUDENT,\n",
    "    encoder_weights=ENCODER_WEIGHTS,  # You can set this to None if you want to train from scratch\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")\n",
    "student_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcabc592a2add6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, metrics, and optimizer for the student model\n",
    "student_loss_fn = NamedDiceLoss(mode='multiclass')\n",
    "metrics = [IoU(threshold=0.5)]\n",
    "student_optimizer = torch.optim.Adam(student_model.parameters(), lr=0.0001)\n",
    "# Early Stopping Initialization\n",
    "early_stopping = EarlyStopping(optimizer=student_optimizer, patience=30, verbose=True)\n",
    "# Training loop for the student model\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    student_model.train()\n",
    "    train_loss = 0\n",
    "    train_iou = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_loader):\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "        # Get student predictions\n",
    "        student_output = student_model(x_batch)\n",
    "\n",
    "        # Compute the loss for the student model\n",
    "        loss = student_loss_fn(student_output, y_batch)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        student_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        student_optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        train_loss += loss.item()\n",
    "        # Compute IoU for the batch\n",
    "        y_pred = torch.argmax(student_output, dim=1)  # Shape: (N, H, W)\n",
    "        y_true = y_batch.squeeze(1)  # Remove channel dimension if present\n",
    "        iou = IoU()(y_pred, y_true)\n",
    "        train_iou += iou.item()\n",
    "\n",
    "    # Compute average training loss and IoU\n",
    "    train_loss /= len(train_loader)\n",
    "    train_iou /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    student_model.eval()\n",
    "    val_loss = 0\n",
    "    val_iou = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE)\n",
    "\n",
    "            # Get student predictions\n",
    "            student_output = student_model(x_batch)\n",
    "\n",
    "            # Compute the validation loss\n",
    "            loss = student_loss_fn(student_output, y_batch)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            val_loss += loss.item()\n",
    "            y_pred = torch.argmax(student_output, dim=1)\n",
    "            y_true = torch.argmax(y_batch, dim=1)\n",
    "            iou = IoU()(y_pred, y_true)\n",
    "            val_iou += iou.item()\n",
    "\n",
    "    # Compute average validation loss and IoU\n",
    "    val_loss /= len(val_loader)\n",
    "    val_iou /= len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch} - Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}')\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(val_loss, student_model, 'student_model_psp_0_0_0.pth')\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daaec55cd1a697a",
   "metadata": {},
   "source": [
    "## Train Student Model with Knowledge Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57ff69a3def944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T03:21:44.679260Z",
     "start_time": "2024-12-18T03:21:42.216829Z"
    }
   },
   "outputs": [],
   "source": [
    "teacher_model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")\n",
    "# teacher_model.load_state_dict(torch.load('teacher_model.pth'))\n",
    "teacher_model.to(DEVICE)\n",
    "teacher_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90fe47ebaa06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the student model\n",
    "ENCODER_STUDENT = 'mobilenet_v2'\n",
    "student_model = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER_STUDENT,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")\n",
    "student_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f06d01860c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the student's segmentation loss function\n",
    "student_loss_fn = NamedDiceLoss(mode='multiclass')\n",
    "\n",
    "# Define optimizer and metrics for the student model\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=0.0001)\n",
    "metrics = [IoU(threshold=0.5)]\n",
    "# Early Stopping Initialization\n",
    "early_stopping = EarlyStopping(optimizer=optimizer, patience=50, verbose=True)\n",
    "\n",
    "# Set teacher model to evaluation mode and prevent training updates\n",
    "teacher_model.eval()\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False  # Ensure teacher model's parameters are not updated\n",
    "\n",
    "# Initialize the custom distillation loss\n",
    "distillation_loss_alpha_fn = GradCAMDistillationLossAlpha(\n",
    "    student_loss_fn=student_loss_fn,\n",
    "    teacher_model=teacher_model,\n",
    "    student_model=student_model,\n",
    "    distillation_weight=0.1,\n",
    "    soft_label_weight=0,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    student_model.train()  # Set student model to training mode\n",
    "    training_loss = 0.0\n",
    "    training_iou = 0.0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(train_loader):\n",
    "        x_batch = x_batch.to(DEVICE)\n",
    "        y_batch = y_batch.to(DEVICE).squeeze(1)\n",
    "\n",
    "        # Forward pass for the student model\n",
    "        student_output = student_model(x_batch)\n",
    "\n",
    "        # Compute the total loss (including Grad-CAM loss)\n",
    "        loss = distillation_loss_alpha_fn(student_output, y_batch, x_batch)\n",
    "\n",
    "        # Zero the gradients, backpropagate, and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for monitoring\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        # Compute IoU for the batch\n",
    "        y_pred = torch.argmax(student_output, dim=1)\n",
    "        iou = IoU()(y_pred, y_batch)\n",
    "        training_iou += iou.item()\n",
    "\n",
    "    training_loss /= len(train_loader)\n",
    "    training_iou /= len(train_loader)\n",
    "\n",
    "    # Validation loop\n",
    "    student_model.eval()  # Set student model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_iou = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.to(DEVICE)\n",
    "            y_batch = y_batch.to(DEVICE).squeeze(1)\n",
    "\n",
    "            # Forward pass for the student model\n",
    "            student_output = student_model(x_batch)\n",
    "\n",
    "            # Compute the student's segmentation loss\n",
    "            loss = student_loss_fn(student_output, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            y_pred = torch.argmax(student_output, dim=1)\n",
    "            iou = IoU()(y_pred, y_batch)\n",
    "            val_iou += iou.item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_iou /= len(val_loader)\n",
    "\n",
    "    print(\n",
    "        f'Epoch {epoch} - Train Loss: {training_loss:.4f}, Train IoU: {training_iou:.4f}, Val Loss: {val_loss:.4f}, Val IoU: {val_iou:.4f}')\n",
    "\n",
    "    early_stopping(val_loss, student_model, 'student_model_mbnv2_01_0_1.pth')\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e961abf86234c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5274c3ba5fd4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:04:46.133397Z",
     "start_time": "2024-12-18T01:04:46.131324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load the model from a given checkpoint path\n",
    "def load_model(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to load the model from a given checkpoint path\n",
    "def load_model_wo_state_dict(model, checkpoint_path):\n",
    "    model = torch.load(checkpoint_path)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88e2179986dd216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:04:46.974218Z",
     "start_time": "2024-12-18T01:04:46.558024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the student model\n",
    "ENCODER_TEACHER = 'resnet101'\n",
    "teacher_model_base = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER_TEACHER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592430074ce5e57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:10:42.218773Z",
     "start_time": "2024-12-18T01:10:41.695097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the student model\n",
    "ENCODER_STUDENT = 'mobilenet_v2'\n",
    "student_model_base = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER_STUDENT,\n",
    "    encoder_weights=ENCODER_WEIGHTS,  # You can set this to None if you want to train from scratch\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")\n",
    "student_model_base_no_cam = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER_STUDENT,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")\n",
    "student_model_base_cam = smp.DeepLabV3Plus(\n",
    "    encoder_name=ENCODER_STUDENT,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=len(CLASSES),\n",
    "    activation=ACTIVATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a6b2a88865217",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:11:08.513451Z",
     "start_time": "2024-12-18T01:11:08.398748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the student and teacher models\n",
    "student_model_no_no = load_model(student_model_base, 'student_model_mbnv2_0_0_0.pth')\n",
    "student_model_cam = load_model(student_model_base_cam, 'student_model_mbnv2_01_0_1.pth')\n",
    "student_model_no_cam = load_model(student_model_base_no_cam, 'student_model_mbnv2_0_01_1.pth')\n",
    "# teacher_model = load_model(teacher_model_base, 'teacher_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88449c1bc70d78",
   "metadata": {},
   "source": [
    "## Calculate Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e201ff292307407",
   "metadata": {},
   "source": [
    "### FLOPs and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb47ca4aa8e6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "\n",
    "def analyze_model_complexity(model, input_shape=(3, 512, 512)):\n",
    "    \"\"\"\n",
    "    Analyze model complexity including FLOPs and parameters.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        input_shape: Tuple of (channels, height, width) for input image\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing model complexity metrics\n",
    "    \"\"\"\n",
    "    macs, params = get_model_complexity_info(\n",
    "        model,\n",
    "        input_shape,\n",
    "        as_strings=True,\n",
    "        print_per_layer_stat=True,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Convert string representations to numeric values\n",
    "    macs_numeric = float(macs.split()[0])\n",
    "    params_numeric = float(params.split()[0])\n",
    "\n",
    "    # Calculate FLOPs (multiply-adds × 2)\n",
    "    flops = macs_numeric * 2\n",
    "\n",
    "    metrics = {\n",
    "        'flops': f'{flops:.2f} GFLOPs',\n",
    "        'params': params,\n",
    "        'macs': macs,\n",
    "        'flops_numeric': flops,\n",
    "        'params_numeric': params_numeric,\n",
    "        'macs_numeric': macs_numeric\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_model_analysis(metrics):\n",
    "    \"\"\"\n",
    "    Print model analysis in a formatted way.\n",
    "\n",
    "    Args:\n",
    "        metrics: Dictionary containing model complexity metrics\n",
    "    \"\"\"\n",
    "    print(\"\\nModel Complexity Analysis:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"FLOPs: {metrics['flops']}\")\n",
    "    print(f\"Parameters: {metrics['params']}\")\n",
    "    print(f\"MACs: {metrics['macs']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3279a4ac88e1d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your saved model first\n",
    "student_model_base_cam.eval()\n",
    "\n",
    "# Analyze the model\n",
    "metrics = analyze_model_complexity(student_model_base_cam)\n",
    "print_model_analysis(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83243114fa697ad4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:04:59.920954Z",
     "start_time": "2024-12-18T01:04:59.917478Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_iou(model, dataloader, device, classes):\n",
    "    iou_metric = IoU(threshold=0.5)\n",
    "    iou_scores = {cls: [] for cls in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, gt_mask) in enumerate(dataloader):\n",
    "            image, gt_mask = image.to(device), gt_mask.to(device)\n",
    "            pr_mask = model(image).squeeze().cpu().numpy()\n",
    "            pr_mask = np.argmax(pr_mask, axis=0)\n",
    "\n",
    "            gt_mask = gt_mask.squeeze().cpu().numpy()\n",
    "\n",
    "            if pr_mask.shape != gt_mask.shape:\n",
    "                print(f\"Shape mismatch: pr_mask shape {pr_mask.shape}, gt_mask shape {gt_mask.shape}\")\n",
    "                continue\n",
    "\n",
    "            for idx, cls in enumerate(classes):\n",
    "                gt_mask_filtered = (gt_mask == idx).astype(float)\n",
    "                pr_mask_filtered = (pr_mask == idx).astype(float)\n",
    "\n",
    "                gt_mask_tensor = torch.tensor(gt_mask_filtered, device=device, dtype=torch.float32).unsqueeze(\n",
    "                    0).unsqueeze(0)\n",
    "                pr_mask_tensor = torch.tensor(pr_mask_filtered, device=device, dtype=torch.float32).unsqueeze(\n",
    "                    0).unsqueeze(0)\n",
    "\n",
    "                iou_score = iou_metric(pr_mask_tensor, gt_mask_tensor).item()\n",
    "                iou_scores[cls].append(iou_score)\n",
    "\n",
    "    avg_iou_scores = {cls: np.mean(scores) for cls, scores in iou_scores.items()}\n",
    "    miou = np.mean(list(avg_iou_scores.values()))\n",
    "\n",
    "    return avg_iou_scores, miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977ef21f4aade82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:05:00.581829Z",
     "start_time": "2024-12-18T01:05:00.579941Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_metric(model, dataloader, device, classes, model_name, dataset_name):\n",
    "    avg_iou_scores, miou = calculate_iou(model, dataloader, device, classes)\n",
    "\n",
    "    print(f\"\\nIoU Scores for each category in {dataset_name} using {model_name}:\")\n",
    "    for cls, score in avg_iou_scores.items():\n",
    "        print(f\"{cls}: {score:.4f}\")\n",
    "    print(f\"Mean IoU for {dataset_name} using {model_name}: {miou:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf680c389daf754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:05:05.099385Z",
     "start_time": "2024-12-18T01:05:05.091571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define preprocessing function\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "# Datasets and dataloaders\n",
    "batch_size = 1  # Set batch size to 1 for IoU calculations as in the original code\n",
    "\n",
    "# Train dataset and dataloader\n",
    "train_dataset = VOCDataset(\n",
    "    x_train_dir,\n",
    "    y_train_dir,\n",
    "    classes=CLASSES,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Validation dataset and dataloader\n",
    "val_dataset = VOCDataset(\n",
    "    x_val_dir,\n",
    "    y_val_dir,\n",
    "    classes=CLASSES,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Test dataset and dataloader\n",
    "test_dataset = VOCDataset(\n",
    "    x_test_dir,\n",
    "    y_test_dir,\n",
    "    classes=CLASSES,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc3e0d1a4ece63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7641606ba150a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T01:51:46.631245Z",
     "start_time": "2024-12-18T01:11:15.386826Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate each model on each dataset\n",
    "models = {\n",
    "    \"Student Model without KD\": student_model_no_no,\n",
    "    \"Student Model with Grad-CAM\": student_model_cam,\n",
    "    \"Student Model without Grad-CAM\": student_model_no_cam,\n",
    "    # \"Teacher Model\": teacher_model\n",
    "}\n",
    "datasets = {\n",
    "    \"Training Set\": train_loader,\n",
    "    \"Validation Set\": val_loader,\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for dataset_name, loader in datasets.items():\n",
    "        evaluate_model_metric(model, loader, DEVICE, CLASSES, model_name, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea5b1c932d7ba9",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f341823e117b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denormalize function (if input is normalized) for better visualization\n",
    "def denormalize(image_tensor, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    image_tensor = image_tensor.clone().detach().cpu()\n",
    "    for t, m, s in zip(image_tensor, mean, std):\n",
    "        t.mul_(s).add_(m)  # Denormalize each channel\n",
    "    return image_tensor.clamp(0, 1)  # Clip to valid range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905d3690a0f0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_iou_per_sample(pred_masks, gt_masks, num_classes):\n",
    "    \"\"\"\n",
    "    Computes the mean IoU per sample over all classes.\n",
    "\n",
    "    Args:\n",
    "        pred_masks (torch.Tensor): Predicted masks of shape [batch_size, H, W].\n",
    "        gt_masks (torch.Tensor): Ground truth masks of shape [batch_size, H, W].\n",
    "        num_classes (int): Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Mean IoU for each sample in the batch.\n",
    "    \"\"\"\n",
    "    batch_size = pred_masks.size(0)\n",
    "    iou_scores = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        pred = pred_masks[i]  # [H, W]\n",
    "        gt = gt_masks[i]  # [H, W]\n",
    "\n",
    "        iou_per_class = []\n",
    "        for cls in range(num_classes):\n",
    "            pred_cls = (pred == cls)\n",
    "            gt_cls = (gt == cls)\n",
    "\n",
    "            intersection = (pred_cls & gt_cls).sum().item()\n",
    "            union = (pred_cls | gt_cls).sum().item()\n",
    "            if union == 0:\n",
    "                iou = float('nan')  # Avoid division by zero\n",
    "            else:\n",
    "                iou = intersection / union\n",
    "            iou_per_class.append(iou)\n",
    "\n",
    "        # Mean IoU over classes for this sample\n",
    "        mean_iou = np.nanmean(iou_per_class)\n",
    "        iou_scores.append(mean_iou)\n",
    "\n",
    "    return iou_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e027ca608b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = np.array([\n",
    "    (0, 0, 0),  # background\n",
    "    (128, 0, 0),  # aeroplane\n",
    "    (0, 128, 0),  # bicycle\n",
    "    (128, 128, 0),  # bird\n",
    "    (0, 0, 128),  # boat\n",
    "    (128, 0, 128),  # bottle\n",
    "    (0, 128, 128),  # bus\n",
    "    (128, 128, 128),  # car\n",
    "    (64, 0, 0),  # cat\n",
    "    (192, 0, 0),  # chair\n",
    "    (64, 128, 0),  # cow\n",
    "    (192, 128, 0),  # dining table\n",
    "    (64, 0, 128),  # dog\n",
    "    (192, 0, 128),  # horse\n",
    "    (64, 128, 128),  # motorbike\n",
    "    (192, 128, 128),  # person\n",
    "    (0, 64, 0),  # potted plant\n",
    "    (128, 64, 0),  # sheep\n",
    "    (0, 192, 0),  # sofa\n",
    "    (128, 192, 0),  # train\n",
    "    (0, 64, 128),  # tv/monitor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25424812b4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_custom_colormap(segmentation_mask, label_map):\n",
    "    \"\"\"\n",
    "    Maps class indices in the segmentation mask to RGB colors using the custom label map.\n",
    "    :param segmentation_mask: 2D array of class indices\n",
    "    :param label_map: Array of RGB color tuples\n",
    "    :return: RGB image\n",
    "    \"\"\"\n",
    "    h, w = segmentation_mask.shape\n",
    "    color_mapped = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for class_id, color in enumerate(label_map):\n",
    "        color_mapped[segmentation_mask == class_id] = color\n",
    "    return color_mapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff1957f4ada3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over multiple batches\n",
    "i = 0\n",
    "for x_sample, y_sample in train_loader:\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break\n",
    "\n",
    "    x_sample = x_sample.to(DEVICE)\n",
    "    y_sample = y_sample.to(DEVICE)\n",
    "    x_sample.requires_grad = True  # Enable gradients for Grad-CAM if necessary\n",
    "\n",
    "    # Generate predictions and masks for all models\n",
    "    with torch.no_grad():\n",
    "        student_output_no_no = student_model_no_no(x_sample)\n",
    "        student_output_cam = student_model_cam(x_sample)\n",
    "        student_output_no_cam = student_model_no_cam(x_sample)\n",
    "        teacher_output = teacher_model(x_sample)\n",
    "\n",
    "    # Generate masks by taking the argmax along the class dimension\n",
    "    student_masks_no_no = torch.argmax(student_output_no_no, dim=1, keepdim=True).float().squeeze(1)\n",
    "    student_masks_cam = torch.argmax(student_output_cam, dim=1, keepdim=True).float().squeeze(1)\n",
    "    student_masks_no_cam = torch.argmax(student_output_no_cam, dim=1, keepdim=True).float().squeeze(1)\n",
    "    teacher_masks = torch.argmax(teacher_output, dim=1, keepdim=True).float().squeeze(1)\n",
    "\n",
    "    # Ground truth mask\n",
    "    gt_masks = y_sample.squeeze(1)  # [batch_size, H, W]\n",
    "\n",
    "    # Compute per-sample mean IoU for each model\n",
    "    iou_no_no = compute_mean_iou_per_sample(student_masks_no_no, gt_masks, num_classes)\n",
    "    iou_cam = compute_mean_iou_per_sample(student_masks_cam, gt_masks, num_classes)\n",
    "    iou_no_cam = compute_mean_iou_per_sample(student_masks_no_cam, gt_masks, num_classes)\n",
    "    iou_teacher = compute_mean_iou_per_sample(teacher_masks, gt_masks, num_classes)\n",
    "\n",
    "    # Compute Grad-CAM heatmaps for all models\n",
    "    student_heatmap_no_no = compute_gradcam_heatmap(\n",
    "        model=student_model_no_no,\n",
    "        target_layer=student_model_no_no.decoder.block1,\n",
    "        input_tensor=x_sample,\n",
    "        masks=student_masks_no_no\n",
    "    )\n",
    "\n",
    "    student_heatmap_cam = compute_gradcam_heatmap(\n",
    "        model=student_model_cam,\n",
    "        target_layer=student_model_cam.decoder.block1,\n",
    "        input_tensor=x_sample,\n",
    "        masks=student_masks_cam\n",
    "    )\n",
    "\n",
    "    student_heatmap_no_cam = compute_gradcam_heatmap(\n",
    "        model=student_model_no_cam,\n",
    "        target_layer=student_model_no_cam.decoder.block1,\n",
    "        input_tensor=x_sample,\n",
    "        masks=student_masks_no_cam\n",
    "    )\n",
    "\n",
    "    teacher_heatmap = compute_gradcam_heatmap(\n",
    "        model=teacher_model,\n",
    "        target_layer=teacher_model.decoder.block1,\n",
    "        input_tensor=x_sample,\n",
    "        masks=teacher_masks\n",
    "    )\n",
    "\n",
    "    # Convert heatmaps to tensors\n",
    "    student_heatmap_no_no = torch.from_numpy(student_heatmap_no_no).float().to(DEVICE)\n",
    "    student_heatmap_cam = torch.from_numpy(student_heatmap_cam).float().to(DEVICE)\n",
    "    student_heatmap_no_cam = torch.from_numpy(student_heatmap_no_cam).float().to(DEVICE)\n",
    "    teacher_heatmap = torch.from_numpy(teacher_heatmap).float().to(DEVICE)\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(4, 4, 1)\n",
    "    original_image = denormalize(x_sample.squeeze())\n",
    "    plt.imshow(np.transpose(original_image.cpu().numpy(), (1, 2, 0)))  # Convert CHW to HWC\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Ground truth mask\n",
    "    plt.subplot(4, 4, 2)\n",
    "    gt_colored_mask = apply_custom_colormap(gt_masks[0].cpu().numpy().astype(int), label_map)\n",
    "    plt.imshow(gt_colored_mask)\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Student mask with CAM\n",
    "    plt.subplot(4, 4, 3)\n",
    "    student_colored_cam = apply_custom_colormap(student_masks_cam.squeeze(0).cpu().numpy().astype(int), label_map)\n",
    "    plt.imshow(student_colored_cam)\n",
    "    plt.title(f\"Student Mask (with CAM)\\nIoU: {iou_cam[0]:.4f}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Grad-CAM heatmap for student with CAM\n",
    "    plt.subplot(4, 4, 4)\n",
    "    plt.imshow(student_heatmap_cam.squeeze(0).cpu().numpy(), cmap='jet')  # Keep jet for Grad-CAM\n",
    "    plt.title(\"Grad-CAM Heatmap (with CAM)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Student mask without CAM\n",
    "    plt.subplot(4, 4, 5)\n",
    "    student_colored_no_cam = apply_custom_colormap(student_masks_no_cam.squeeze(0).cpu().numpy().astype(int), label_map)\n",
    "    plt.imshow(student_colored_no_cam)\n",
    "    plt.title(f\"Student Mask (no CAM)\\nIoU: {iou_no_cam[0]:.4f}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Grad-CAM heatmap for student without CAM\n",
    "    plt.subplot(4, 4, 6)\n",
    "    plt.imshow(student_heatmap_no_cam.squeeze(0).cpu().numpy(), cmap='jet')\n",
    "    plt.title(\"Grad-CAM Heatmap (no CAM)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Teacher mask\n",
    "    plt.subplot(4, 4, 7)\n",
    "    teacher_colored_mask = apply_custom_colormap(teacher_masks.squeeze(0).cpu().numpy().astype(int), label_map)\n",
    "    plt.imshow(teacher_colored_mask)\n",
    "    plt.title(f\"Teacher Mask\\nIoU: {iou_teacher[0]:.4f}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Grad-CAM heatmap for teacher\n",
    "    plt.subplot(4, 4, 8)\n",
    "    plt.imshow(teacher_heatmap.squeeze(0).cpu().numpy(), cmap='jet')\n",
    "    plt.title(\"Grad-CAM Heatmap (Teacher)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Student mask without anything\n",
    "    plt.subplot(4, 4, 9)\n",
    "    student_colored_no_no = apply_custom_colormap(student_masks_no_no.squeeze(0).cpu().numpy().astype(int), label_map)\n",
    "    plt.imshow(student_colored_no_no)\n",
    "    plt.title(f\"Student Mask (no no)\\nIoU: {iou_no_no[0]:.4f}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Grad-CAM heatmap for student without anything\n",
    "    plt.subplot(4, 4, 10)\n",
    "    plt.imshow(student_heatmap_no_no.squeeze(0).cpu().numpy(), cmap='jet')\n",
    "    plt.title(\"Grad-CAM Heatmap (no no)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b598f225eb115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
